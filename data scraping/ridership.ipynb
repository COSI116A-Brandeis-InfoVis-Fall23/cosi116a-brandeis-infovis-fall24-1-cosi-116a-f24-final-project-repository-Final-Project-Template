{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/jasminehuang/Desktop/datasets to be used/Rail_Ridership_by_Season_Time_Period_RouteLine_and_Stop_5316095790925663588.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_peak_data(df, day_type, day_types):\n",
    "    # Filter data for the specified day type\n",
    "    filtered_data = df[df['day_type_name'].isin(day_types)]\n",
    "\n",
    "    # Calculate overall average ons for each station\n",
    "    average_ons_per_station = filtered_data.groupby('stop_name')['average_ons'].mean().reset_index()\n",
    "    average_ons_per_station.rename(columns={'average_ons': f'{day_type}_overall_average_ons'}, inplace=True)\n",
    "    \n",
    "    # Find the peak time for each station\n",
    "    peak_time_data = filtered_data.groupby(['stop_name', 'time_period_name'])['average_ons'].sum().reset_index()\n",
    "    peak_time_per_station = peak_time_data.loc[\n",
    "        peak_time_data.groupby('stop_name')['average_ons'].idxmax()\n",
    "    ]\n",
    "    \n",
    "    # Merge overall average with peak time data\n",
    "    result = pd.merge(average_ons_per_station, peak_time_per_station, on='stop_name')\n",
    "    result.rename(columns={\n",
    "        'time_period_name': f'{day_type}_peak_time',\n",
    "        'average_ons': f'{day_type}_peak_time_average_ons'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Step 2: Calculate data for weekdays and weekends\n",
    "weekday_data = calculate_peak_data(df, 'weekday', ['weekday'])\n",
    "weekend_data = calculate_peak_data(df, 'weekend', ['saturday', 'sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_mapping_df = pd.read_csv(\"/Users/jasminehuang/Desktop/datasets to be used/cleaned_mbta_stops.csv\")\n",
    "\n",
    "weekday_data = pd.merge(weekday_data, station_mapping_df[['stop_name', 'station_id']], on='stop_name', how='left')\n",
    "weekend_data = pd.merge(weekend_data, station_mapping_df[['stop_name', 'station_id']], on='stop_name', how='left')\n",
    "\n",
    "# Replace stop_name with station_id\n",
    "weekday_data['stop_name'] = weekday_data['station_id']\n",
    "weekend_data['stop_name'] = weekend_data['station_id']\n",
    "\n",
    "# Drop extra station_id column\n",
    "weekday_data.drop(columns=['station_id'], inplace=True)\n",
    "weekend_data.drop(columns=['station_id'], inplace=True)\n",
    "\n",
    "weekday_data = weekday_data.dropna(subset=['stop_name'])\n",
    "weekend_data = weekend_data.dropna(subset=['stop_name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>weekday_overall_average_ons</th>\n",
       "      <th>weekday_peak_time</th>\n",
       "      <th>weekday_peak_time_average_ons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place-aport</td>\n",
       "      <td>443.703704</td>\n",
       "      <td>MIDDAY_BASE</td>\n",
       "      <td>4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place-alfcl</td>\n",
       "      <td>670.888889</td>\n",
       "      <td>AM_PEAK</td>\n",
       "      <td>14424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>place-alsgr</td>\n",
       "      <td>40.944444</td>\n",
       "      <td>MIDDAY_BASE</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>place-andrw</td>\n",
       "      <td>362.851852</td>\n",
       "      <td>AM_PEAK</td>\n",
       "      <td>4752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>place-aqucl</td>\n",
       "      <td>289.129630</td>\n",
       "      <td>PM_PEAK</td>\n",
       "      <td>5674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>place-welln</td>\n",
       "      <td>429.462963</td>\n",
       "      <td>AM_PEAK</td>\n",
       "      <td>8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>place-wlsta</td>\n",
       "      <td>141.925926</td>\n",
       "      <td>AM_PEAK</td>\n",
       "      <td>3031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>place-wondl</td>\n",
       "      <td>390.851852</td>\n",
       "      <td>AM_PEAK</td>\n",
       "      <td>8385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>place-wimnl</td>\n",
       "      <td>126.925926</td>\n",
       "      <td>AM_PEAK</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>place-woodl</td>\n",
       "      <td>21.814815</td>\n",
       "      <td>AM_PEAK</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stop_name  weekday_overall_average_ons weekday_peak_time  \\\n",
       "0    place-aport                   443.703704       MIDDAY_BASE   \n",
       "1    place-alfcl                   670.888889           AM_PEAK   \n",
       "2    place-alsgr                    40.944444       MIDDAY_BASE   \n",
       "3    place-andrw                   362.851852           AM_PEAK   \n",
       "4    place-aqucl                   289.129630           PM_PEAK   \n",
       "..           ...                          ...               ...   \n",
       "115  place-welln                   429.462963           AM_PEAK   \n",
       "116  place-wlsta                   141.925926           AM_PEAK   \n",
       "117  place-wondl                   390.851852           AM_PEAK   \n",
       "118  place-wimnl                   126.925926           AM_PEAK   \n",
       "119  place-woodl                    21.814815           AM_PEAK   \n",
       "\n",
       "     weekday_peak_time_average_ons  \n",
       "0                             4898  \n",
       "1                            14424  \n",
       "2                              722  \n",
       "3                             4752  \n",
       "4                             5674  \n",
       "..                             ...  \n",
       "115                           8217  \n",
       "116                           3031  \n",
       "117                           8385  \n",
       "118                           1786  \n",
       "119                            288  \n",
       "\n",
       "[118 rows x 4 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Map time periods to start times\n",
    "weekday_data = pd.merge(\n",
    "    weekday_data,\n",
    "    time_period_df[['time_period_name', 'period_start_time']],\n",
    "    left_on='weekday_peak_time',\n",
    "    right_on='time_period_name',\n",
    "    how='left'\n",
    ")\n",
    "weekday_data['weekday_peak_time'] = weekday_data['period_start_time']\n",
    "weekday_data.drop(columns=['time_period_name', 'period_start_time'], inplace=True)\n",
    "\n",
    "weekend_data = pd.merge(\n",
    "    weekend_data,\n",
    "    time_period_df[['time_period_name', 'period_start_time']],\n",
    "    left_on='weekend_peak_time',\n",
    "    right_on='time_period_name',\n",
    "    how='left'\n",
    ")\n",
    "weekend_data['weekend_peak_time'] = weekend_data['period_start_time']\n",
    "weekend_data.drop(columns=['time_period_name', 'period_start_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Combine weekday and weekend data into a nested structure\n",
    "combined = {}\n",
    "\n",
    "# Helper function to strip prefixes from dictionary keys\n",
    "def strip_prefix(data, prefix):\n",
    "    return {key.replace(f\"{prefix}_\", \"\"): value for key, value in data.items()}\n",
    "\n",
    "for station in set(weekday_data['stop_name']).union(weekend_data['stop_name']):\n",
    "    station_weekday_data = weekday_data[weekday_data['stop_name'] == station]\n",
    "    station_weekend_data = weekend_data[weekend_data['stop_name'] == station]\n",
    "\n",
    "    combined[station] = {\n",
    "        'weekday': strip_prefix(station_weekday_data.iloc[0].to_dict(), 'weekday') \n",
    "                   if not station_weekday_data.empty else {},\n",
    "        'weekend': strip_prefix(station_weekend_data.iloc[0].to_dict(), 'weekend') \n",
    "                   if not station_weekend_data.empty else {}\n",
    "    }\n",
    "\n",
    "# Clean up duplicate 'stop_name' keys in the dictionaries\n",
    "for station, data in combined.items():\n",
    "    data['weekday'].pop('stop_name', None)\n",
    "    data['weekend'].pop('stop_name', None)\n",
    "\n",
    "# Step 7: Export to JSON\n",
    "import json\n",
    "with open(\"peak_time_ridership.json\", \"w\") as f:\n",
    "    json.dump(combined, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.10 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bea2c380e3a6efb02d12d5076df8d4cb837586fdbbd52ce5de213d1972803b3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
